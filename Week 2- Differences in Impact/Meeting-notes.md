# Meeting Notes (12th July, 2021)

## Group 2

### Exercise on understanding Framing Bias

* In a burning building, would you take an action that'd save 400 out of 500 with certainty, or take the chance where everyone can be saved with 90% probability.
  
* Another case, 2 options:
100 people die with certainty, or there's a 10% chance all 500 die, but 90% chance no-one dies.

    The interesting thing is even though both are the same problems, our mind reacts very differently to both. Just framing the question as saving 400 instead of saying killing 100 can trigger us to choose different options - Framing bias

### Readings discussion

* Sunk cost fallacy vs Marginal benefit mindset
  * If a lot of money has been poured into a cause already and it's not generating results, instead of trying to generate results, it might be a better idea to redirect that money explore alternative problems or approaches
    * Example of project to prevent suicides in military families

* Should we always listen to the people whose problem we're solving?
  * The community whose problem we're solving will most likely have a different worldview than us, and sometimes their values might not align with humanitarian values. (For instance, casteism, or slavery)
  * One way of thinking about it is that often people don't understand what they want or need. (Apple vs Google's approach to designing products analogy) Could be their limited exposure, their own personal interests etc. Here, getting a leader from the community on your side can be beneficial

  * In certain such situations the likelihood of success might be very minute, but we also have to keep in mind that the rewards if it actually becomes successful makes it worth the risk

### Exercise to understand how much impact can we have

* Interesting to see a positive angle on triage. By choosing A vs B we're saving X more people vs making the choice on who to let suffer

* Even though from calculations we might choose one charity over the other, in real life, just giving this amount to organization that has expertise and the understanding of where this money will have the most marginal impact might be a better strategy

* Another perspective could be to look at the return on investment, even financially, since if you're able to use a given income to generate more income, then that can lead to ever better outcomes

* If you can earn enough money by retiring early, you might open up new opportunities which didn't exist earlier

### Limitations of the guestimates used

* Can't assume one leader can be replaced for another without change of outcomes. However, EA has started factoring in into their research and decisions

* While making the assumption all lives are equal, we're missing out on second and third order effects of these choices. Also, it'd probably have been better off for the world if Hitler didn't exist

* Can't really predict what would have happened otherwise, because of the complexity of the world (Think butterfly effect)

* Factoring in future generations of humans (longtermism) is also hard to account for
